{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for Tests other than MGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the simultions utilizing the import statement below (for this only linear was utilized in this case). Refer to the simulations jupyter notebook for more information about the simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mgcpy.benchmarks.simulations import linear_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCorr, MCorr, Mantel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the `DCorr` class from the mgcpy package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mgcpy.independence_tests.dcorr import DCorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance based correlation is the type of correlation which MGC is based upon. A detailed description of the motivation and derivations is in Appendix A.III in the following paper: https://arxiv.org/pdf/1609.05148.pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the other tests, simply create an `DCorr` object with `'biased'` as the `which_test` parameter and then call the test statistic method. This is done below, by utilizing a simulation and calculating the Dcorr's test statistic from that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCorr's test statistic: 1.00\n"
     ]
    }
   ],
   "source": [
    "x, y = linear_sim(100, 1, noise=0)\n",
    "\n",
    "dcorr = DCorr(which_test='biased')\n",
    "test_stat, _ = dcorr.test_statistic(x, y, is_fast=True)\n",
    "print(\"DCorr's test statistic: %.2f\" % test_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-values are calculated via permutation tests as with other packages. This is done by permutting $y$ and calculating the test statistic. The number of times that the test statistics are greater than or equal to null divided by the replication factor is equal to the p-value. This is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCorr p-value: 0.00\n"
     ]
    }
   ],
   "source": [
    "p_value = dcorr.p_value(x, y)[0]\n",
    "print(\"DCorr p-value: %.2f\" % p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original DCorr is biased and an unbiased version (modified dcorr, i.e. mcorr) is proposed here: https://www.sciencedirect.com/science/article/pii/S0047259X13000262. MCorr uses a slightly different centering scheme compared to DCorr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the other tests, simply create an `DCorr` object with `'unbiased'` as the `which_test` parameter and then call the test statistic method. This is done below, by utilizing a simulation and calculating the MCorr's test statistic from that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCorr's test statistic: 1.00\n"
     ]
    }
   ],
   "source": [
    "x, y = linear_sim(100, 1, noise=0)\n",
    "\n",
    "mcorr = DCorr(which_test='unbiased')\n",
    "test_stat = mcorr.test_statistic(x, y)[0]\n",
    "print(\"MCorr's test statistic: %.2f\" % test_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was shown that the p-value of MCorr can be obtained by a t-test, avoiding the computation cost of performing a full permutation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCorr p-value: 0.00\n"
     ]
    }
   ],
   "source": [
    "p_value = mcorr.p_value(x, y)[0]\n",
    "print(\"MCorr p-value: %.2f\" % p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mantel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mantel is another distance-based correlation method that uses a much simpler centering scheme compared to DCorr and MCorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the other tests, simply create an `DCorr` object with `'mantel'` as the `which_test` parameter and then call the test statistic method. This is done below, by utilizing a simulation and calculating the Mantel's test statistic from that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mantel's test statistic: 0.26\n"
     ]
    }
   ],
   "source": [
    "x, y = linear_sim(100, 1)\n",
    "\n",
    "mantel = DCorr(which_test='mantel')\n",
    "test_stat = mantel.test_statistic(x, y)[0]\n",
    "print(\"Mantel's test statistic: %.2f\" % test_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-values are calculated via permutation tests as with other packages. This is done by permutting $y$ and calculating the test statistic. The number of times that the test statistics are greater than or equal to null divided by the replication factor is equal to the p-value. This is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mantel p-value: 0.00\n"
     ]
    }
   ],
   "source": [
    "p_value = mantel.p_value(x, y)[0]\n",
    "print(\"Mantel p-value: %.2f\" % p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HHG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HHG test statistic was developed as specified in Heller, et. al. (2012). For more information about the test statistic, refer to the documentation specified in the R package here: https://cran.r-project.org/web/packages/HHG/vignettes/HHG.html.\n",
    "\n",
    "Essentially, the test takes the distance between two points, $P_{0}$ and $P_{1}$, and calculates how far each of the other data points in the data set are from $P_{0}$ and $P_{1}$ and organizes it in the following table:\n",
    "<table>\n",
    "  <tr>\n",
    "    <th style=\"width:200px\"><center></center></th>\n",
    "    <th style=\"width:200px\"><center>$d_{y}(P_{0},\\cdot) \\leq d_{y}(P_{0},P_{1})$</center></th> \n",
    "    <th style=\"width:200px\"><center>$d_{y}(P_{0},\\cdot) > d_{y}(P_{0},P_{1})$</center></th>\n",
    "    <th style=\"width:200px\"><center></center></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th style=\"width:200px\"><center>$d_{x}(P_{0},\\cdot) \\leq d_{x}(P_{0},P_{1})$</center></th>\n",
    "    <td style=\"width:200px\"><center>$A_{11}(P_{0}, P_{1})$</center></td> \n",
    "    <td style=\"width:200px\"><center>$A_{12}(P_{0}, P_{1})$</center></td>\n",
    "    <th style=\"width:200px\"><center>$A_{1\\cdot}(P_{0}, P_{1})$</center></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th style=\"width:200px\"><center>$d_{x}(P_{0},\\cdot) > d_{x}(P_{0},P_{1})$</center></th>\n",
    "    <td style=\"width:200px\"><center>$A_{21}(P_{0}, P_{1})$</center></td> \n",
    "    <td style=\"width:200px\"><center>$A_{22}(P_{0}, P_{1})$</center></td>\n",
    "    <th style=\"width:200px\"><center>$A_{2\\cdot}(P_{0}, P_{1})$</center></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th style=\"width:200px\"><center></center></th>\n",
    "    <th style=\"width:200px\"><center>$A_{\\cdot 1}(P_{0}, P_{1})$</center></td> \n",
    "    <th style=\"width:200px\"><center>$A_{\\cdot 2}(P_{0}, P_{1})$</center></td>\n",
    "    <th style=\"width:200px\"><center>$N-2$</center></th>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "A Chi square test statistic is then computed from table and the HHG test statistic is simply the sum of all the test statistics calculated:\n",
    "\n",
    "$$S(i, j)=\\frac{(N-2)(A_{12}A_{21}-A_{11}A_{22})}{A_{1\\cdot}A_{2\\cdot}A_{\\cdot 1}A_{\\cdot 2}}$$\n",
    "\n",
    "$$T=\\sum_{i=1}^{N}\\sum_{j=1, i \\neq j}^{N}S(i, j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the `HHG` class from the mgcpy package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mgcpy.independence_tests.hhg import HHG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the other tests, simply create an `HHG` object and then call the test statistic method. This is done below, by utilizing a simulation and calculating the HHG test statistic from that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'test_statistic_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3204f2eb6b1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhhg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHHG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_stat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhhg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_statistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HHG test statistic: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtest_stat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/mgcpy/independence_tests/hhg.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, compute_distance_matrix)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mcompute_distance_matrix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFunctionType\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \"\"\"\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mIndependenceTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_distance_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhich_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hhg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/mgcpy/independence_tests/abstract_class.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, compute_distance_matrix)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_distance_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_statistic_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_statistic_metadata_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_value_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'test_statistic_'"
     ]
    }
   ],
   "source": [
    "x, y = linear_sim(10, 1)\n",
    "\n",
    "hhg = HHG()\n",
    "test_stat = hhg.test_statistic(x, y)[0]\n",
    "print(\"HHG test statistic: %.2f\" % test_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-values are calculated via permutation tests as with other packages. This is done by permutting $y$ and calculating the test statistic. The number of times that the test statistics are greater than or equal to null divided by the replication factor is equal to the p-value. This is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_value = hhg.p_value(x, y)[0]\n",
    "print(\"HHG p-value: %.2f\" % p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kendall, Spearman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the `KendallSpearman` class from the mgcpy package. Note that these tests utilize the `scipy.stats` implementation of the kendall and spearman tests and were included out of convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mgcpy.independence_tests.kendall_spearman import KendallSpearman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kendall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kendall tau coefficient was calculated utilizing the `scipy.stats` implementation. Further explanation this test can be found here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html. <b>Note: The inputs for this test must be 1 dimensional.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the other tests, simply create an `KendallSpearman` object with `'kendall'` as the `which_test` parameter and then call the test statistic method. This is done below, by utilizing a simulation and calculating the Kendall's test statistic from that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = linear_sim(100, 1)\n",
    "\n",
    "kendall = KendallSpearman(which_test='kendall')\n",
    "test_stat = kendall.test_statistic(x, y)[0]\n",
    "print(\"Kendall's test statistic: %.2f\" % test_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-values are calculated via permutation tests as with other packages. This is done by permutting $y$ and calculating the test statistic. The number of times that the test statistics are greater than or equal to null divided by the replication factor is equal to the p-value. This is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_value = kendall.p_value(x, y)[0]\n",
    "print(\"Pearson's p-value: %.2f\" % p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spearman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Spearman rho coefficient was calculated utilizing the `scipy.stats` implementation. Further explanation this test can be found here: https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.spearmanr.html. <b>Note: The inputs for this test must be 1 dimensional.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the other tests, simply create an `KendallSpearman` object with `'spearman'` as the `which_test` parameter and then call the test statistic method. This is done below, by utilizing a simulation and calculating the Spearman's test statistic from that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = linear_sim(100, 1)\n",
    "\n",
    "spearman = KendallSpearman(which_test='spearman')\n",
    "test_stat = spearman.test_statistic(x, y)[0]\n",
    "print(\"Spearman's test statistic: %.2f\" % test_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-values are calculated via permutation tests as with other packages. This is done by permutting $y$ and calculating the test statistic. The number of times that the test statistics are greater than or equal to null divided by the replication factor is equal to the p-value. This is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_value = spearman.p_value(x, y)[0]\n",
    "print(\"Pearson's p-value: %.2f\" % p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson's, RV, and CCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the `RVCorr` class from the mgcpy package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mgcpy.independence_tests.rv_corr import RVCorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\cov}{\\mathrm{cov}}$The Pearson's correlation was calculated utilizing the `scipy.stats` implementation. Further explanation this test can be found here: https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.pearsonr.html.\n",
    "\n",
    "This is a test returns a statistic between -1 and 1 and measures the linear correlation between two vectors. <b>Note: The inputs for this test must be 1 dimensional.</b>\n",
    "\n",
    "The correlation is calculated via the following formula:\n",
    "\n",
    "$$\\rho _{X, Y}=\\frac{\\cov(X, Y)}{\\sigma _{X}\\sigma _{Y}}$$\n",
    "\n",
    "where $\\cov$ is the covariance, $\\sigma _{X}$ is the standard deviation of $X$, and $\\sigma _{Y}$ is the standard deviation of $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the other tests, simply create an `RVCorr` object with `'pearson'` as the `which_test` parameter and then call the test statistic method. This is done below, by utilizing a simulation and calculating the Pearson's test statistic from that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = linear_sim(100, 1)\n",
    "\n",
    "pearson = RVCorr(which_test='pearson')\n",
    "test_stat = pearson.test_statistic(x, y)[0]\n",
    "print(\"Pearson's test statistic: %.2f\" % test_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-values are calculated via permutation tests as with other packages. This is done by permutting $y$ and calculating the test statistic. The number of times that the test statistics are greater than or equal to null divided by the replication factor is equal to the p-value. This is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_value = pearson.p_value(x, y)[0]\n",
    "print(\"Pearson's p-value: %.2f\" % p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\COVV}{\\mathrm{COVV}}$$\\newcommand{\\Tr}{\\mathrm{Tr}}$$\\newcommand{\\VAV}{\\mathrm{VAV}}$$\\newcommand{\\RV}{\\mathrm{RV}}$This test is essentially the a multivariate generalization of the square pearson's correlation coefficient. It returns values between 0 and 1. If $X$ and $Y$ are matrices of centered column vectors with covariance:\n",
    "\n",
    "$$\\Sigma _{XY}=E(X^{T}Y)$$\n",
    "\n",
    "Then the scaled covariance ($\\COVV$) is:\n",
    "\n",
    "$$\\COVV(X,Y)=\\Tr(\\Sigma _{XY}\\Sigma _{YX})$$\n",
    "\n",
    "Then the scaled-valued variance is defined similarly ($\\COVV$):\n",
    "\n",
    "$$\\VAV(X)=\\Tr(\\Sigma _{XX}^{2})$$\n",
    "\n",
    "Then, the RV Coefficient is defined as:\n",
    "\n",
    "$$\\RV(X,Y)=\\frac{\\COVV(X,Y)}{\\sqrt{\\VAV(X)\\VAV(Y)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the other tests, simply create an `RVCorr` object with `'rv'` as the `which_test` parameter and then call the test statistic method. This is done below, by utilizing a simulation and calculating the RV test statistic from that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = linear_sim(100, 3)\n",
    "\n",
    "rv = RVCorr(which_test='rv')\n",
    "test_stat = rv.test_statistic(x, y)[0]\n",
    "print(\"RV test statistic: %.2f\" % test_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-values are calculated via permutation tests as with other packages. This is done by permutting $y$ and calculating the test statistic. The number of times that the test statistics are greater than or equal to null divided by the replication factor is equal to the p-value. This is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_value = rv.p_value(x, y)[0]\n",
    "print(\"RV p-value: %.2f\" % p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\cov}{\\mathrm{cov}}$This test infers information from the cross-covariance matrices of random variables. It is a generalization of the RV test and can be considered the most general case of almost all statistical tests.\n",
    "\n",
    "If $\\Sigma _{XX}=\\cov(X, X)$ and $\\Sigma _{YY}=\\cov(Y, Y)$, then:\n",
    "\n",
    "$$\\frac{a^{T}\\Sigma _{XX}b}{\\sqrt{a^{T}\\Sigma _{XX}a}\\sqrt{b^{T}\\Sigma _{YY}b}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the other tests, simply create an `RVCorr` object with `'cca'` as the `which_test` parameter and then call the test statistic method. This is done below, by utilizing a simulation and calculating the CCA test statistic from that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = linear_sim(100, 6)\n",
    "\n",
    "cca = RVCorr(which_test='cca')\n",
    "test_stat = cca.test_statistic(x, y)[0]\n",
    "print(\"CCA test statistic: %.2f\" % test_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-values are calculated via permutation tests as with other packages. This is done by permutting $y$ and calculating the test statistic. The number of times that the test statistics are greater than or equal to null divided by the replication factor is equal to the p-value. This is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_value = cca.p_value(x, y)[0]\n",
    "print(\"CCA p-value: %.2f\" % p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
