{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Demo: DCorr-X and MGC-X\n",
    "In this notebook, we demonstrate the cross-distance correlation (`DCorrX`) test and the multiscale graph correlation for time series (`MGCX`) test for independence of time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from mgcpy.independence_tests.dcorrx import DCorrX\n",
    "from mgcpy.independence_tests.mgcx import MGCX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to compute and print DCorrX nd MGCX output values, given X and Y:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_dcorrx(X, Y, max_lag):\n",
    "    dcorrx = DCorrX(max_lag = max_lag, which_test = 'unbiased')\n",
    "    dcorrx_statistic, metadata = dcorrx.test_statistic(X, Y)\n",
    "    p_value, _ = dcorrx.p_value(X, Y)\n",
    "    optimal_lag = metadata['optimal_lag']\n",
    "\n",
    "    print(\"DCorrX test statistic:\", dcorrx_statistic)\n",
    "    print(\"P Value:\", p_value)\n",
    "    print(\"Optimal Lag:\", optimal_lag)\n",
    "\n",
    "def compute_mgcx(X, Y, max_lag):\n",
    "    mgcx = MGCX(max_lag = max_lag)\n",
    "    mgcx_statistic, metadata = mgcx.test_statistic(X, Y)\n",
    "    p_value, _ = mgcx.p_value(X, Y)\n",
    "    optimal_lag = metadata['optimal_lag']\n",
    "    optimal_scale = metadata['optimal_scale']\n",
    "    \n",
    "    print(\"MGCX test statistic:\", mgcx_statistic)\n",
    "    print(\"P Value:\", p_value)\n",
    "    print(\"Optimal Lag:\", optimal_lag)\n",
    "    print(\"Optimal Scale:\", optimal_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulate data. X and Y are n-by-1 matrices.\n",
    "n = 10\n",
    "X = np.random.normal(0.0, 1.0, n).reshape(n,1)\n",
    "Y = np.random.normal(0.0, 1.0, n).reshape(n,1)\n",
    "\n",
    "max_lag = 0\n",
    "compute_mgcx(X, Y, max_lag)\n",
    "compute_dcorrx(X, Y, max_lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: simulate data `X` and `Y` in the form of `n`-by-`p` and `n`-by-`q` matrices respectively, where `n` is the sample size.** In the following cells, we simulate different time series processes and estimate the power of the test at varying choices of sample size. Additionally, we compare against the Ljung-Box test of correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to simulate time series.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indep_ar1(n, phi = 0.5, sigma2 = 1.0):\n",
    "    # X_t and Y_t are univarite AR(1) with phi = 0.5 for both.\n",
    "    # Innovations follow N(0, sigma2).\n",
    "    \n",
    "    # Innovations.\n",
    "    epsilons = np.random.normal(0.0, sigma2, n)\n",
    "    etas = np.random.normal(0.0, sigma2, n)\n",
    "    \n",
    "    X = np.zeros(n)\n",
    "    Y = np.zeros(n)\n",
    "    X[0] = epsilons[0]\n",
    "    Y[0] = etas[0]\n",
    "    \n",
    "    # AR(1) process.\n",
    "    for t in range(1,n):\n",
    "        X[t] = phi*X[t-1] + epsilons[t]\n",
    "        Y[t] = phi*Y[t-1] + etas[t]\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lin_dep_ar1(n, phi = 0.5, sigma2 = 1.0):\n",
    "    # X_t and Y_t are together a bivarite AR(1) with Phi = [0 0.5; 0.5 0].\n",
    "    # Innovations follow N(0, sigma2).\n",
    "    \n",
    "    # Innovations.\n",
    "    epsilons = np.random.normal(0.0, sigma2, n)\n",
    "    etas = np.random.normal(0.0, sigma2, n)\n",
    "    \n",
    "    X = np.zeros(n)\n",
    "    Y = np.zeros(n)\n",
    "    X[0] = epsilons[0]\n",
    "    Y[0] = etas[0]\n",
    "    \n",
    "    # AR(1) process.\n",
    "    for t in range(1,n):\n",
    "        X[t] = phi*Y[t-1] + epsilons[t]\n",
    "        Y[t] = phi*X[t-1] + etas[t]\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nonlin_dep_lag_m(n, m = 1, phi_m = 1, sigma2 = 0.5):\n",
    "    # X_t and Y_t are together a bivarite nonlinear process.\n",
    "    # Innovations follow N(0, sigma2).\n",
    "    \n",
    "    # Innovations.\n",
    "    epsilons = np.random.normal(0.0, sigma2, n)\n",
    "    etas = np.random.normal(0.0, sigma2, n)\n",
    "    \n",
    "    X = np.zeros(n)\n",
    "    Y = np.zeros(n)\n",
    "    for t in range(m):\n",
    "        Y[t] = etas[t]\n",
    "    \n",
    "    # AR(1) process.\n",
    "    for t in range(m,n):\n",
    "        X[t] = phi_m*epsilons[t]*Y[t-m]\n",
    "        Y[t] = etas[t]\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to run the Ljung-Box test of dependence using cross-correlations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LJUNG_BOX():\n",
    "    def __init__(self, max_lag = 0):\n",
    "        self.max_lag = max_lag\n",
    "        self.test_stat = None\n",
    "    def test_statistic(self, X, Y):\n",
    "        n = len(X)\n",
    "        test_statistic = 0\n",
    "        for j in range(self.max_lag+1):\n",
    "                lead_X = X[j:n]\n",
    "                lag_Y = Y[0:(n-j)]\n",
    "                test_statistic += ((np.corrcoef(lead_X,lag_Y)[1,0])**2 / (n-j))\n",
    "        self.test_stat = test_statistic*n*(n+2)\n",
    "        metadata = {}\n",
    "        return self.test_stat, metadata\n",
    "    def p_value(self, X, Y, replication_factor = 100):\n",
    "        test_stat, metadata = self.test_statistic(X, Y)\n",
    "        pval = 1 - chi2.cdf(test_stat, df = self.max_lag+4)\n",
    "        metadata = {}\n",
    "        return pval,  metadata\n",
    "    def get_test_statistic(self):\n",
    "        return self.test_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Power as a function of `n` of the tests on each process.** Probability of correctly rejecting the null hypothesis that the time series are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_filename(s):\n",
    "    # Take title and format as filename.\n",
    "    filename = list(s.lower())\n",
    "    for i in range(len(filename)):\n",
    "        if filename[i] == \" \":\n",
    "            filename[i] = \"_\"\n",
    "    return(''.join(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def power_curve(sample_sizes, powers, alpha, title, savefig = True):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"n\")\n",
    "    plt.ylabel(\"Rejection Probability\")\n",
    "    \n",
    "    plt.plot(sample_sizes, powers['dcorrx'], linestyle = '-', color = 'blue')\n",
    "    # plt.plot(sample_sizes, powers['lb'], linestyle = ':', color = 'red')\n",
    "    plt.plot(sample_sizes, powers['mgcx'], linestyle = '--', color = 'green')\n",
    "    ax.legend(['DCorr-X', 'MGC-X'], loc = 'upper left') # Add back LB\n",
    "    \n",
    "    ax.axhline(y=alpha, color = 'black', linestyle = '--')\n",
    "    ax.axhline(y=1, color = 'black', linestyle = '--')\n",
    "    if savefig:\n",
    "        filename = \"power_curve_%s.png\" % format_filename(title)\n",
    "        plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimal lag as a function of `n` of the tests on each process.** Probability of detecting the final lag at which there is dependence between the time series, i.e. the window of dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimal_lag_curve(sample_sizes, lag_probs, title, savefig = True):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"n\")\n",
    "    plt.ylabel(\"Probability of Detecting Correct Lag\")\n",
    "    \n",
    "    plt.plot(sample_sizes, lag_probs['dcorrx'], linestyle = '-', color = 'blue')\n",
    "    plt.plot(sample_sizes, lag_probs['mgcx'], linestyle = '--', color = 'green')\n",
    "    ax.legend(['Cross-DCorr', 'MGC-TS'], loc = 'upper left')\n",
    "    \n",
    "    ax.axhline(y=1, color = 'black', linestyle = '--')\n",
    "    if savefig:\n",
    "        filename = \"optimal_lag_%s.png\" % format_filename(title)\n",
    "        plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution of optimal lags for finite `n`.** The empirical distribution of the optimal lag returned by the test, visualized over the true Pearson's correlation of `X_t` and `Y_t` at each lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opt_lag_dist_stems(optimal_lags, true_correlations, title, color = 'powderblue', savefig = True):\n",
    "    # True correlations at various lags.\n",
    "    j = range(true_correlations.shape[0])\n",
    "    markerline, stemlines, baseline = plt.stem(j, true_correlations, '-k')\n",
    "    plt.setp(baseline, 'color', 'k', 'linewidth', 1)\n",
    "    plt.setp(markerline, 'markerfacecolor', 'k')\n",
    "    plt.xlabel('Lag j')\n",
    "    plt.ylabel(\"Corr(X(t), Y(t-j)) / Freq. of Optimal Lag Estimates\")\n",
    "    \n",
    "    # Optimal lab predictions.\n",
    "    weights = np.ones_like(optimal_lags)/float(len(optimal_lags))\n",
    "    plt.hist(optimal_lags, \n",
    "             bins = np.arange(len(true_correlations))-0.5, \n",
    "             weights = weights, \n",
    "             align = 'mid',\n",
    "             edgecolor ='black',\n",
    "             color = color)\n",
    "    \n",
    "    filename = \"optimal_lag_dist_stems_%s.png\" % format_filename(title)\n",
    "    if savefig:\n",
    "        plt.title(title)\n",
    "        plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opt_lag_dist(optimal_lags, title, color = 'lightgreen', savefig = True):\n",
    "    # True correlations at various lags.\n",
    "    plt.xlabel('Lag j')\n",
    "    plt.ylabel(\"Freq. of Optimal Lag Estimates\")\n",
    "    \n",
    "    # Optimal lab predictions.\n",
    "    weights = np.ones_like(optimal_lags)/float(len(optimal_lags))\n",
    "    plt.hist(optimal_lags, \n",
    "             bins = np.arange(len(true_correlations))-0.5, \n",
    "             weights = weights, \n",
    "             align = 'mid',\n",
    "             edgecolor ='black',\n",
    "             color = color)\n",
    "    \n",
    "    filename = \"optimal_lag_dist_%s.png\" % format_filename(title)\n",
    "    if savefig:\n",
    "        plt.title(title)\n",
    "        plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Full experiment, simulating the above time series, and counting the rejections and optimal lag detections by each test (as a function of `n`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combining all time series simulations.\n",
    "processes = {\n",
    "    'indep_ar1'  : { 'simulate': indep_ar1,  'name': \"Independent AR(1)\", 'true_lag': -1},\n",
    "    'lin_dep_ar1': { 'simulate': lin_dep_ar1,  'name': \"Correlated AR(1)\", 'true_lag': 1},\n",
    "    'nonlin_dep_lag_m' : { 'simulate': nonlin_dep_lag_m,  'name': \"Nonlinearly Dependent at Lag 1\", 'true_lag': 1}, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Experiment 1: parameters.\n",
    "sample_sizes  = range(10,100,10)\n",
    "num_sims      = 100\n",
    "num_bootstrap = 100\n",
    "alpha         = 0.05\n",
    "maxlag        = 1\n",
    "compute_pval  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize objects and holders.\n",
    "random.seed(123)\n",
    "dcorrx      = DCorrX(max_lag = maxlag)\n",
    "mgcx    = MGCX(max_lag = maxlag)\n",
    "lb        = LJUNG_BOX(max_lag = maxlag)\n",
    "tests     = {'dcorrx': dcorrx, 'mgcx': mgcx, 'lb': lb}\n",
    "powers    = {'dcorrx': np.zeros(len(sample_sizes)), \n",
    "             'mgcx': np.zeros(len(sample_sizes))}\n",
    "lag_probs = {'dcorrx': np.zeros(len(sample_sizes)), \n",
    "             'mgcx': np.zeros(len(sample_sizes))}\n",
    "\n",
    "# Run experiments.\n",
    "for p in ['lin_dep_ar1']:\n",
    "    process = processes[p]\n",
    "    simulate = process['simulate']\n",
    "    for i in range(len(sample_sizes)):\n",
    "        rejects  = {'dcorrx': 0.0, 'mgcx': 0.0, 'lb': 0.0}\n",
    "        opt_lags = {'dcorrx': np.zeros(num_sims), 'mgcx': np.zeros(num_sims)}\n",
    "        n = sample_sizes[i]\n",
    "        print(\"Estimating power/lag detection prob. at n =\", str(n), end = \"\")\n",
    "        \n",
    "        # Simulate time series and count rejections.\n",
    "        for t in range(num_sims):\n",
    "            print('.', end='')\n",
    "            X, Y = simulate(n)\n",
    "            \n",
    "            for r in ['dcorrx', 'mgcx']:\n",
    "                test = tests[r]\n",
    "                test_statistic, metadata = test.test_statistic(X, Y)\n",
    "                detects = opt_lags[r]\n",
    "                detects[t] = metadata['optimal_lag']\n",
    "                if compute_pval:\n",
    "                    p_value, _ = test.p_value(X, Y, replication_factor = num_bootstrap)\n",
    "                    if (p_value < alpha): rejects[r] += 1\n",
    "        for r in ['dcorrx', 'mgcx']: \n",
    "            power = powers[r]\n",
    "            power[i] = rejects[r]/num_sims\n",
    "            if r is not 'lb':\n",
    "                lag_prob = lag_probs[r]\n",
    "                lag_prob[i] = np.count_nonzero(opt_lags[r] == process['true_lag'])/num_sims\n",
    "        print(\"\")\n",
    "        \n",
    "    # Display power estimates and probility of detecting the correct lag.\n",
    "    if compute_pval:\n",
    "        power_curve(sample_sizes, powers, alpha, process['name'])\n",
    "    optimal_lag_curve(sample_sizes, lag_probs, process['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Experiment 2: parameters.\n",
    "sample_sizes  = range(10,185,20)\n",
    "num_sims      = 100\n",
    "num_bootstrap = 100\n",
    "alpha         = 0.05\n",
    "maxlag        = 1\n",
    "compute_pval  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize objects and holders.\n",
    "dcorrx  = DCorrX(max_lag = maxlag)\n",
    "mgcx    = MGCX(max_lag = maxlag)\n",
    "lb      = LJUNG_BOX(max_lag = maxlag)\n",
    "tests   = {'dcorrx': dcorrx, 'mgcx': mgcx, 'lb': lb}\n",
    "powers  = {'dcorrx': np.zeros(len(sample_sizes)), \n",
    "           'mgcx': np.zeros(len(sample_sizes)), \n",
    "           'lb': np.zeros(len(sample_sizes))}\n",
    "lag_probs = {'dcorrx': np.zeros(len(sample_sizes)), \n",
    "             'mgcx': np.zeros(len(sample_sizes))}\n",
    "\n",
    "# Run experiments.\n",
    "for p in ['nonlin_dep_lag_m']:\n",
    "    process = processes[p]\n",
    "    simulate = process['simulate']\n",
    "    for i in range(len(sample_sizes)):\n",
    "        rejects  = {'dcorrx': 0.0, 'mgcx': 0.0, 'lb': 0.0}\n",
    "        opt_lags = {'dcorrx': np.zeros(num_sims), 'mgcx': np.zeros(num_sims)}\n",
    "        n = sample_sizes[i]\n",
    "        print(\"Estimating power/lag detection prob. at n =\", str(n), end = \"\")\n",
    "        \n",
    "        # Simulate time series and count rejections.\n",
    "        for t in range(num_sims):\n",
    "            print('.', end='')\n",
    "            X, Y = simulate(n)\n",
    "            \n",
    "            for r in ['dcorrx', 'mgcx']:\n",
    "                test = tests[r]\n",
    "                if r is not 'lb':\n",
    "                    test_statistic, metadata = test.test_statistic(X, Y)\n",
    "                    detects = opt_lags[r]\n",
    "                    detects[t] = metadata['optimal_lag']\n",
    "                if compute_pval:\n",
    "                    p_value, _ = test.p_value(X, Y, replication_factor = num_bootstrap)\n",
    "                    if (p_value < alpha): rejects[r] += 1\n",
    "        for r in ['dcorrx', 'mgcx']:\n",
    "            power = powers[r]\n",
    "            power[i] = rejects[r]/num_sims\n",
    "            if r is not 'lb':\n",
    "                lag_prob = lag_probs[r]\n",
    "                lag_prob[i] = np.count_nonzero(opt_lags[r] == process['true_lag'])/num_sims\n",
    "        print(\"\")\n",
    "        \n",
    "    # Display power estimates and probility of detecting the correct lag.\n",
    "    if compute_pval:\n",
    "        power_curve(sample_sizes, powers, alpha, process['name'])\n",
    "    optimal_lag_curve(sample_sizes, lag_probs, process['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyzing the distribution of optimal lags returned by the tests.** We see how that the optimal lags returned by the test corresponds with the true dependence structure of the simulated time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lin_dep_ar3(n, phi_1 = 0.5, phi_3 = 0.5, sigma2 = 1.0):\n",
    "    # X_t and Y_t are together a bivarite AR(3).\n",
    "    # Innovations follow N(0, sigma2).\n",
    "    \n",
    "    # Innovations.\n",
    "    epsilons = np.random.normal(0.0, sigma2, n)\n",
    "    etas = np.random.normal(0.0, sigma2, n)\n",
    "    \n",
    "    X = np.zeros(n)\n",
    "    Y = np.zeros(n)\n",
    "    for s in range(3):\n",
    "        X[s] = epsilons[s]\n",
    "        Y[s] = etas[s]\n",
    "    \n",
    "    # AR(1) process.\n",
    "    for t in range(3,n):\n",
    "        X[t] = phi_1*Y[t-1] + phi_3*Y[t-3] + epsilons[t]\n",
    "        Y[t] = phi_1*X[t-1] + phi_3*X[t-3] + etas[t]\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correlated AR(3)\n",
    "phi_1 = 0.8\n",
    "phi_3 = 0.1\n",
    "sigma2 = 1.0\n",
    "M = 10\n",
    "num_sims = 100\n",
    "\n",
    "# Determine true correlations.\n",
    "rho_XY = np.zeros(M+1)\n",
    "rho_X = np.zeros(M+1)\n",
    "rho_X[0] = 1\n",
    "rho_XY[1] = phi_1 / (1 - phi_3*(phi_1 + phi_3))\n",
    "rho_X[2] = (phi_1 + phi_3)*rho_XY[1]\n",
    "for j in range(3, M+1):\n",
    "    if j%2:\n",
    "        rho_XY[j] = phi_1*rho_X[j-1] + phi_3*rho_X[j-3]\n",
    "    else:\n",
    "        rho_X[j] = phi_1*rho_XY[j-1] + phi_3*rho_XY[j-3]\n",
    "\n",
    "dcorrx = DCorrX(max_lag = M)\n",
    "mgcx = MGCX(max_lag = M)\n",
    "true_correlations = rho_XY\n",
    "optimal_lags_dcorrx = np.zeros(num_sims)\n",
    "optimal_lags_mgcx = np.zeros(num_sims)\n",
    "\n",
    "# Run experiments.\n",
    "for n in [15, 30, 60]:\n",
    "    for t in range(num_sims):\n",
    "        X, Y = lin_dep_ar3(n, phi_1 = phi_1, phi_3 = phi_3, sigma2 = sigma2)\n",
    "        test_statistic, metadata = dcorrx.test_statistic(X, Y)\n",
    "        optimal_lags_dcorrx[t] = metadata['optimal_lag']\n",
    "        test_statistic, metadata = mgcx.test_statistic(X, Y)\n",
    "        optimal_lags_mgcx[t] = metadata['optimal_lag']\n",
    "    title_dcorrx = \"Dcorr-X, Crosscorrelated AR(3), n = %d\" % n\n",
    "    title_mgcx = \"MGC-X, Crosscorrelated AR(3), n = %d\" % n\n",
    "    opt_lag_dist_stems(optimal_lags_dcorrx, true_correlations, title = title_dcorrx, color = 'powderblue')\n",
    "    opt_lag_dist_stems(optimal_lags_mgcx, true_correlations, title = title_mgcx, color = 'lightgreen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulate a nonlinear process, estimate the Cross Distance Correlation Function, and show that the optimal lag is correct for large n.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma2 = 1.0\n",
    "M = 10\n",
    "m = 3\n",
    "num_sims = 100\n",
    "\n",
    "dcorrx = DCorrX(max_lag = M)\n",
    "mgcx = MGCX(max_lag = M)\n",
    "optimal_lags_dcorrx = np.zeros(num_sims)\n",
    "optimal_lags_mgcx = np.zeros(num_sims)\n",
    "\n",
    "# Run experiments.\n",
    "for n in [25, 50, 100]:\n",
    "    for t in range(num_sims):\n",
    "        X, Y = nonlin_dep_lag_m(n, m, phi_m = 0.8, sigma2 = 1.0)\n",
    "        test_statistic, metadata = dcorrx.test_statistic(X, Y)\n",
    "        optimal_lags_dcorrx[t] = metadata['optimal_lag']\n",
    "        test_statistic, metadata = mgcx.test_statistic(X, Y)\n",
    "        optimal_lags_mgcx[t] = metadata['optimal_lag']\n",
    "    title_dcorrx = \"Dcorr-X, Nonlinearly Dependent at Lag 3, n = %d\" % n\n",
    "    title_mgcx = \"MGC-X, Nonlinearly Dependent at Lag 3, n = %d\" % n\n",
    "    opt_lag_dist(optimal_lags_dcorrx, title = title_dcorrx, color = 'powderblue')\n",
    "    opt_lag_dist(optimal_lags_mgcx, title = title_mgcx, color = 'lightgreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
